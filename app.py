import streamlit as st
import pandas as pd
import gspread
import json
import re
import io
from datetime import datetime, timedelta
from oauth2client.service_account import ServiceAccountCredentials
import pytz

# ---------- åˆæœŸè¨­å®š ----------
st.set_page_config(page_title="æ¡å¯¸ãƒ‡ãƒ¼ã‚¿ç®¡ç†", layout="wide")
page = st.sidebar.selectbox("ãƒšãƒ¼ã‚¸ã‚’é¸æŠ", ["æ¡å¯¸å…¥åŠ›", "æ¡å¯¸æ¤œç´¢", "å•†å“ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", "æ¡å¯¸ãƒ˜ãƒƒãƒ€ãƒ¼åˆæœŸåŒ–"])

# ---------- Google Sheetsèªè¨¼ ----------
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
json_key = json.loads(st.secrets["GOOGLE_CREDENTIALS"])
creds = ServiceAccountCredentials.from_json_keyfile_dict(json_key, scope)
client = gspread.authorize(creds)
spreadsheet = client.open("æ¡å¯¸ç®¡ç†ãƒ‡ãƒ¼ã‚¿")

# ---------- ã‚«ãƒ†ã‚´ãƒªåˆ¥ç†æƒ³é † ----------
ideal_order_dict = {
    "ã‚¸ãƒ£ã‚±ãƒƒãƒˆ": ["è‚©å¹…", "èƒ¸å¹…", "èƒ´å›²", "è¢–ä¸ˆ", "ç€ä¸ˆ"],
    "ãƒ‘ãƒ³ãƒ„": ["ã‚¦ã‚¨ã‚¹ãƒˆ", "è‚¡ä¸Š", "è‚¡ä¸‹", "ãƒ¯ã‚¿ãƒª", "è£¾å¹…"],
    "ãƒ€ã‚¦ãƒ³": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ", "è¥Ÿé«˜"],
    "ãƒ–ãƒ«ã‚¾ãƒ³": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ", "è¥Ÿé«˜"],
    "ã‚³ãƒ¼ãƒˆ": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ", "è¥Ÿé«˜"],
    "ãƒ‹ãƒƒãƒˆ": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ"],
    "ã‚«ãƒƒãƒˆã‚½ãƒ¼": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ"],
    "ãƒ¬ã‚¶ãƒ¼": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ", "è¥Ÿé«˜"],
    "é´": ["å…¨é•·", "æœ€å¤§å¹…"],
    "å·»ç‰©": ["å…¨é•·", "æ¨ªå¹…"],
    "å°ç‰©ãƒ»ãã®ä»–": ["é ­å‘¨ã‚Š", "ãƒ„ãƒ", "é«˜ã•", "æ¨ªå¹…", "ãƒãƒ"],
    "ã‚·ãƒ£ãƒ„": ["è‚©å¹…", "è£„ä¸ˆ", "èƒ¸å¹…", "èƒ´å›²", "è¢–ä¸ˆ", "ç€ä¸ˆ"],
    "ã‚·ãƒ£ãƒ„ã‚¸ãƒ£ã‚±ãƒƒãƒˆ": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ"],
    "ã‚¹ãƒ¼ãƒ„": ["è‚©å¹…", "èƒ¸å¹…", "èƒ´å›²", "è¢–ä¸ˆ", "ç€ä¸ˆ", "ã‚¦ã‚¨ã‚¹ãƒˆ", "è‚¡ä¸Š", "è‚¡ä¸‹", "ãƒ¯ã‚¿ãƒª", "è£¾å¹…"],
    "ãƒ™ãƒ«ãƒˆ": ["å…¨é•·", "ãƒ™ãƒ«ãƒˆå¹…"],
    "åŠè¢–": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "å‰ä¸ˆ", "å¾Œä¸ˆ"]
}

# ---------- è‡ªå‹•ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å‡¦ç†ï¼ˆ30æ—¥ä»¥ä¸Šå‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç§»å‹•ï¼‰ ----------
def archive_old_records():
    try:
        now = datetime.now(pytz.timezone("Asia/Tokyo"))
        cutoff = now - timedelta(days=30)

        result_ws = spreadsheet.worksheet("æ¡å¯¸çµæœ")
        archive_ws = spreadsheet.worksheet("æ¡å¯¸ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–")

        result_df = pd.DataFrame(result_ws.get_all_records())
        if result_df.empty:
            return

        result_df["æ—¥ä»˜_dt"] = pd.to_datetime(result_df["æ—¥ä»˜"], errors='coerce')

        to_archive = result_df[result_df["æ—¥ä»˜_dt"] < cutoff]
        keep = result_df[result_df["æ—¥ä»˜_dt"] >= cutoff]

        if not to_archive.empty:
            archive_existing = pd.DataFrame(archive_ws.get_all_records())
            combined = pd.concat([archive_existing, to_archive.drop(columns="æ—¥ä»˜_dt")], ignore_index=True)

            archive_ws.clear()
            archive_ws.update([combined.columns.tolist()] + combined.values.tolist())

            result_ws.clear()
            result_ws.update([keep.drop(columns="æ—¥ä»˜_dt").columns.tolist()] + keep.drop(columns="æ—¥ä»˜_dt").values.tolist())
    except Exception as e:
        st.warning(f"ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

archive_old_records()
# ---------- æ¡å¯¸å…¥åŠ›ãƒšãƒ¼ã‚¸ ----------
if page == "æ¡å¯¸å…¥åŠ›":
    st.title("âœï¸ æ¡å¯¸å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ")
    try:
        master_df = pd.DataFrame(spreadsheet.worksheet("å•†å“ãƒã‚¹ã‚¿").get_all_records())
        result_df = pd.DataFrame(spreadsheet.worksheet("æ¡å¯¸çµæœ").get_all_records())

        brand_list = master_df["ãƒ–ãƒ©ãƒ³ãƒ‰"].dropna().unique().tolist()
        selected_brand = st.selectbox("ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’é¸æŠ", brand_list, key="brand_select")
        filtered_df = master_df[master_df["ãƒ–ãƒ©ãƒ³ãƒ‰"] == selected_brand]

        product_ids = filtered_df["ç®¡ç†ç•ªå·"].dropna().unique().tolist()
        selected_pid = st.selectbox("ç®¡ç†ç•ªå·ã‚’é¸æŠ", product_ids, key="pid_select")

        product_row = filtered_df[filtered_df["ç®¡ç†ç•ªå·"] == selected_pid].iloc[0]
        size_options = filtered_df[filtered_df["ç®¡ç†ç•ªå·"] == selected_pid]["ã‚µã‚¤ã‚º"].unique()
        selected_size = st.selectbox("ã‚µã‚¤ã‚º", size_options, key="size_select")

        category = product_row["ã‚«ãƒ†ã‚´ãƒª"]
        template_df = pd.DataFrame(spreadsheet.worksheet("æ¡å¯¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ").get_all_records())
        item_row = template_df[template_df["ã‚«ãƒ†ã‚´ãƒª"] == category]

        if not item_row.empty:
            raw_items = item_row.iloc[0]["æ¡å¯¸é …ç›®"].replace("ã€", ",").split(",")
            all_items = [re.sub(r'ï¼ˆ.*?ï¼‰', '', i).strip() for i in raw_items if i.strip()]
            ideal_order = ideal_order_dict.get(category, [])
            items = [i for i in ideal_order if i in all_items] + [i for i in all_items if i not in ideal_order]

            # ğŸ” é¡ä¼¼ãƒ‡ãƒ¼ã‚¿è‡ªå‹•è£œå®Œ
            def extract_keywords(text):
                return set(re.findall(r'[A-Za-z0-9]+', str(text).upper()))

            keywords = extract_keywords(product_row["å•†å“å"])
            keywords = {k for k in keywords if len(k) >= 3}

            def score(row):
                target_words = extract_keywords(row["å•†å“å"])
                return len(keywords & target_words)

            result_df["score"] = result_df.apply(score, axis=1)
            candidates = result_df[result_df["ã‚µã‚¤ã‚º"].astype(str).str.strip() == str(selected_size).strip()]
            candidates = candidates[candidates["score"] > 0].sort_values("score", ascending=False)
            previous_data = candidates.head(1)

            st.markdown("### æ¡å¯¸å€¤å…¥åŠ›")
            measurements = {}
            for item in items:
                key = f"{item}_{selected_pid}_{selected_size}"
                default = previous_data.iloc[0][item] if not previous_data.empty and item in previous_data.columns else ""
                st.text_input(f"{item} (å‰å›: {default})", value="", key=key)
                measurements[item] = st.session_state.get(key, "")

            if st.button("ä¿å­˜", key="save_button"):
                save_data = {
                    "æ—¥ä»˜": datetime.now().strftime("%Y-%m-%d"),
                    "å•†å“ç®¡ç†ç•ªå·": selected_pid,
                    "ãƒ–ãƒ©ãƒ³ãƒ‰": selected_brand,
                    "ã‚«ãƒ†ã‚´ãƒª": category,
                    "å•†å“å": product_row["å•†å“å"],
                    "ã‚«ãƒ©ãƒ¼": product_row["ã‚«ãƒ©ãƒ¼"],
                    "ã‚µã‚¤ã‚º": selected_size
                }
                save_data.update(measurements)

                result_sheet = spreadsheet.worksheet("æ¡å¯¸çµæœ")
                headers = result_sheet.row_values(1)
                new_row = [save_data.get(h, "") for h in headers]
                result_sheet.append_row(new_row)

                # ãƒã‚¹ã‚¿ã‹ã‚‰å‰Šé™¤
                master_sheet = spreadsheet.worksheet("å•†å“ãƒã‚¹ã‚¿")
                master_all = pd.DataFrame(master_sheet.get_all_records())
                updated_df = master_all[~((master_all["ç®¡ç†ç•ªå·"] == selected_pid) & (master_all["ã‚µã‚¤ã‚º"] == selected_size))]
                master_sheet.clear()
                master_sheet.update([updated_df.columns.tolist()] + updated_df.values.tolist())

                st.success("âœ… æ¡å¯¸ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã€ãƒã‚¹ã‚¿ã‹ã‚‰å‰Šé™¤ã—ã¾ã—ãŸï¼")
        else:
            st.warning("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
# ---------------------
# æ¡å¯¸æ¤œç´¢ãƒšãƒ¼ã‚¸
# ---------------------
elif page == "æ¡å¯¸æ¤œç´¢":
    st.title("ğŸ” æ¡å¯¸çµæœæ¤œç´¢")
    try:
        result_df = pd.DataFrame(spreadsheet.worksheet("æ¡å¯¸çµæœ").get_all_records())
        archive_df = pd.DataFrame(spreadsheet.worksheet("æ¡å¯¸ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–").get_all_records())
        result_df = pd.concat([result_df, archive_df], ignore_index=True)

        selected_brands = st.multiselect("ğŸ”¸ ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’é¸æŠ", sorted(result_df["ãƒ–ãƒ©ãƒ³ãƒ‰"].dropna().astype(str).unique()))
        selected_pids = st.multiselect("ğŸ”¹ ç®¡ç†ç•ªå·ã‚’é¸æŠ", sorted(result_df["å•†å“ç®¡ç†ç•ªå·"].dropna().astype(str).unique()))
        selected_sizes = st.multiselect("ğŸ”º ã‚µã‚¤ã‚ºã‚’é¸æŠ", sorted(result_df["ã‚µã‚¤ã‚º"].dropna().astype(str).unique()))
        keyword = st.text_input("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆå•†å“åã€ç®¡ç†ç•ªå·ãªã©ï¼‰")
        category_filter = st.selectbox("ğŸ“‚ ã‚«ãƒ†ã‚´ãƒªã§è¡¨ç¤ºé …ç›®ã‚’çµã‚‹", ["ã™ã¹ã¦è¡¨ç¤º"] + sorted(result_df["ã‚«ãƒ†ã‚´ãƒª"].dropna().astype(str).unique()))

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if selected_brands:
            result_df = result_df[result_df["ãƒ–ãƒ©ãƒ³ãƒ‰"].astype(str).isin(selected_brands)]
        if selected_pids:
            result_df = result_df[result_df["å•†å“ç®¡ç†ç•ªå·"].astype(str).isin(selected_pids)]
        if selected_sizes:
            result_df = result_df[result_df["ã‚µã‚¤ã‚º"].astype(str).isin(selected_sizes)]
        if keyword:
            result_df = result_df[result_df.apply(lambda row: keyword.lower() in str(row.values).lower(), axis=1)]
        if category_filter != "ã™ã¹ã¦è¡¨ç¤º":
            result_df = result_df[result_df["ã‚«ãƒ†ã‚´ãƒª"].astype(str) == category_filter]

        # é …ç›®é †æ•´åˆ—
        base_cols = ["æ—¥ä»˜", "å•†å“ç®¡ç†ç•ªå·", "ãƒ–ãƒ©ãƒ³ãƒ‰", "ã‚«ãƒ†ã‚´ãƒª", "å•†å“å", "ã‚«ãƒ©ãƒ¼", "ã‚µã‚¤ã‚º"]
        ideal_cols = ideal_order_dict.get(category_filter, [])
        ordered_cols = base_cols + [col for col in ideal_cols if col in result_df.columns] + \
                       [col for col in result_df.columns if col not in base_cols + ideal_cols]
        result_df = result_df[ordered_cols]

        # å…¨ã¦ç©ºã®åˆ—ã‚’å‰Šé™¤
        result_df = result_df.loc[:, ~((result_df == "") | (result_df.isna())).all()]

        st.write(f"ğŸ” æ¤œç´¢çµæœ: {len(result_df)} ä»¶")
        st.dataframe(result_df)

        if not result_df.empty:
            to_excel = io.BytesIO()
            with pd.ExcelWriter(to_excel, engine="openpyxl") as writer:
                result_df.to_excel(writer, index=False, sheet_name="æ¡å¯¸çµæœ")
                writer.sheets["æ¡å¯¸çµæœ"].auto_filter.ref = writer.sheets["æ¡å¯¸çµæœ"].dimensions
            to_excel.seek(0)

            st.download_button(
                label="ğŸ“¥ æ¤œç´¢çµæœã‚’Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=to_excel,
                file_name="æ¡å¯¸æ¤œç´¢çµæœ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    except Exception as e:
        st.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
# ---------------------
# å•†å“ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸
# ---------------------
elif page == "å•†å“ã‚¤ãƒ³ãƒãƒ¼ãƒˆ":
    st.title("ğŸ“¦ å•†å“ãƒã‚¹ã‚¿ï¼šExcelã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨ã‚µã‚¤ã‚ºå±•é–‹")
    uploaded_file = st.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"])
    if uploaded_file:
        df = pd.read_excel(uploaded_file, header=1)
        st.subheader("å…ƒãƒ‡ãƒ¼ã‚¿")
        st.dataframe(df)

        def expand_sizes(df):
            df = df.copy()
            df["ã‚µã‚¤ã‚º"] = df["ã‚µã‚¤ã‚º"].astype(str).str.replace("ã€", ",").str.split(",")
            df["ã‚µã‚¤ã‚º"] = df["ã‚µã‚¤ã‚º"].apply(lambda x: [s.strip() for s in x])
            return df.explode("ã‚µã‚¤ã‚º").reset_index(drop=True)

        expanded_df = expand_sizes(df)
        expanded_df["ã‚µã‚¤ã‚º"] = expanded_df["ã‚µã‚¤ã‚º"].str.strip()

        st.subheader("å±•é–‹å¾Œï¼ˆ1ã‚µã‚¤ã‚º1è¡Œï¼‰")
        st.dataframe(expanded_df)

        if st.button("Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜"):
            try:
                sheet = spreadsheet.worksheet("å•†å“ãƒã‚¹ã‚¿")
                existing_df = pd.DataFrame(sheet.get_all_records())
                combined_df = pd.concat([existing_df, expanded_df], ignore_index=True)
                combined_df.drop_duplicates(subset=["ç®¡ç†ç•ªå·", "ã‚µã‚¤ã‚º"], keep="last", inplace=True)
                sheet.clear()
                sheet.update([combined_df.columns.tolist()] + combined_df.values.tolist())
                st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
            except Exception as e:
                st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
# ---------------------
# æ¡å¯¸ãƒ˜ãƒƒãƒ€ãƒ¼åˆæœŸåŒ–ãƒšãƒ¼ã‚¸
# ---------------------
elif page == "æ¡å¯¸ãƒ˜ãƒƒãƒ€ãƒ¼åˆæœŸåŒ–":
    st.title("ğŸ“‹ æ¡å¯¸çµæœãƒ˜ãƒƒãƒ€ãƒ¼ã‚’åˆæœŸåŒ–")

    headers = ["æ—¥ä»˜", "å•†å“ç®¡ç†ç•ªå·", "ãƒ–ãƒ©ãƒ³ãƒ‰", "ã‚«ãƒ†ã‚´ãƒª", "å•†å“å", "ã‚«ãƒ©ãƒ¼", "ã‚µã‚¤ã‚º"]
    all_items = sorted(set(sum(ideal_order_dict.values(), [])))
    headers.extend(all_items)

    try:
        sheet = spreadsheet.worksheet("æ¡å¯¸çµæœ")
        sheet.clear()
        sheet.append_row(headers)
        st.success("âœ… ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤ã•ã‚Œã¾ã™ï¼‰")
    except Exception as e:
        st.error(f"åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
