import streamlit as st
import pandas as pd
import gspread
import re
import io
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
import streamlit.components.v1 as components  # â˜… è¿½åŠ 

# ãƒšãƒ¼ã‚¸è¨­å®šã¯æœ€åˆã«ï¼
st.set_page_config(page_title="æ¡å¯¸ãƒ‡ãƒ¼ã‚¿ç®¡ç†", layout="wide")

# ğŸ” Secrets ã‹ã‚‰å–å¾—
users = st.secrets["users"]

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.title("ğŸ” ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢")

    username = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
    password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")

    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):
        if username in users and password == users[username]:
            st.session_state.authenticated = True
            st.session_state.username = username
            st.rerun()
        else:
            st.error("âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")
    st.stop()

# â”â”â”â”â” Google Sheetsèªè¨¼ â”â”â”â”â”
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
json_key = st.secrets["GOOGLE_CREDENTIALS"]
creds = ServiceAccountCredentials.from_json_keyfile_dict(json_key, scope)
client = gspread.authorize(creds)
spreadsheet = client.open("æ¡å¯¸ç®¡ç†ãƒ‡ãƒ¼ã‚¿")

# â”â”â”â”â” ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãèª­ã¿è¾¼ã¿é–¢æ•° â”â”â”â”â”
@st.cache_data(ttl=30, show_spinner=False)
def load_master_data():
    return pd.DataFrame(spreadsheet.worksheet("å•†å“ãƒã‚¹ã‚¿").get_all_records())

@st.cache_data(ttl=30, show_spinner=False)
def load_template_data():
    return pd.DataFrame(spreadsheet.worksheet("æ¡å¯¸ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ").get_all_records())

@st.cache_data(ttl=30, show_spinner=False)
def load_result_data():
    return pd.DataFrame(spreadsheet.worksheet("æ¡å¯¸çµæœ").get_all_records())

@st.cache_data(ttl=30, show_spinner=False)
def load_archive_data():
    return pd.DataFrame(spreadsheet.worksheet("æ¡å¯¸ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–").get_all_records())

@st.cache_data(ttl=30, show_spinner=False)
def load_standard_data():
    return pd.DataFrame(spreadsheet.worksheet("åŸºæº–ãƒ‡ãƒ¼ã‚¿").get_all_records())

# â”â”â”â”â” é …ç›®ã®è¡¨ç¤ºé †è¾æ›¸ â”â”â”â”â”
ideal_order_dict = {
    "ã‚¸ãƒ£ã‚±ãƒƒãƒˆ": ["è‚©å¹…", "èƒ¸å¹…", "èƒ´å›²", "è¢–ä¸ˆ", "ç€ä¸ˆ"],
    "ãƒ‘ãƒ³ãƒ„": ["ã‚¦ã‚¨ã‚¹ãƒˆ", "è‚¡ä¸Š", "è‚¡ä¸‹", "ãƒ¯ã‚¿ãƒª", "è£¾å¹…"],
    "ãƒ€ã‚¦ãƒ³": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ", "è¥Ÿé«˜"],
    "ãƒ–ãƒ«ã‚¾ãƒ³": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ", "è¥Ÿé«˜"],
    "ã‚³ãƒ¼ãƒˆ": ["è‚©å¹…", "èƒ¸å¹…", "èƒ´å›²", "è¢–ä¸ˆ", "ç€ä¸ˆ", "è¥Ÿé«˜"],
    "ãƒ‹ãƒƒãƒˆ": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ", "é¦–é«˜"],
    "ã‚«ãƒƒãƒˆã‚½ãƒ¼": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ"],
    "ãƒ¬ã‚¶ãƒ¼": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ", "è¥Ÿé«˜"],
    "é´": ["å…¨é•·", "æœ€å¤§å¹…"],
    "å·»ç‰©": ["å…¨é•·", "æ¨ªå¹…"],
    "å°ç‰©ãƒ»ãã®ä»–": ["é ­å‘¨ã‚Š", "ãƒ„ãƒ", "é«˜ã•", "æ¨ªå¹…", "é«˜ã•", "ãƒãƒ"],
    "ã‚·ãƒ£ãƒ„": ["è‚©å¹…", "è£„ä¸ˆ", "èƒ¸å¹…", "èƒ´å›²", "è¢–ä¸ˆ", "ç€ä¸ˆ"],
    "ã‚·ãƒ£ãƒ„ã‚¸ãƒ£ã‚±ãƒƒãƒˆ": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "ç€ä¸ˆ"],
    "ã‚¹ãƒ¼ãƒ„": ["è‚©å¹…", "èƒ¸å¹…", "èƒ´å›²", "è¢–ä¸ˆ", "ç€ä¸ˆ", "ã‚¦ã‚¨ã‚¹ãƒˆ", "è‚¡ä¸Š", "è‚¡ä¸‹", "ãƒ¯ã‚¿ãƒª", "è£¾å¹…"],
    "ãƒ™ãƒ«ãƒˆ": ["å…¨é•·", "ãƒ™ãƒ«ãƒˆå¹…"],
    "åŠè¢–": ["è‚©å¹…", "èƒ¸å¹…", "è¢–ä¸ˆ", "å‰ä¸ˆ", "å¾Œä¸ˆ"],
    "ãƒ©ã‚°ãƒ©ãƒ³": ["è£„ä¸ˆ", "èƒ¸å¹…", "ç€ä¸ˆ"]
}

# â”â”â”â”â” ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒšãƒ¼ã‚¸åˆ‡ã‚Šæ›¿ãˆ â”â”â”â”â”
page = st.sidebar.selectbox("ãƒšãƒ¼ã‚¸ã‚’é¸æŠ", [
    "æ¡å¯¸å…¥åŠ›", "æ¡å¯¸æ¤œç´¢", "å•†å“ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", "åŸºæº–å€¤ã‚¤ãƒ³ãƒãƒ¼ãƒˆ", "æ¡å¯¸ãƒ˜ãƒƒãƒ€ãƒ¼åˆæœŸåŒ–", "ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç®¡ç†"
])

# ---------------------
# æ¡å¯¸å…¥åŠ›ãƒšãƒ¼ã‚¸
# ---------------------
if page == "æ¡å¯¸å…¥åŠ›":
    st.title("ğŸ“± æ¡å¯¸å…¥åŠ›")

    # 1) å¿…è¦ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    master_df   = load_master_data()
    template_df = load_template_data()
    result_df   = load_result_data()
    archive_df  = load_archive_data()
    combined_df = pd.concat([result_df, archive_df], ignore_index=True)

    # 2) é¸æŠUI
    custom_orders = {
        "ãƒ‘ãƒ³ãƒ„": ["ã‚¦ã‚¨ã‚¹ãƒˆ", "è‚¡ä¸Š", "ãƒ¯ã‚¿ãƒª", "è‚¡ä¸‹", "è£¾å¹…"],
        "ã‚·ãƒ£ãƒ„": ["è‚©å¹…", "èƒ¸å¹…", "èƒ´å›²", "è£„ä¸ˆ", "è¢–ä¸ˆ", "ç€ä¸ˆ"]
    }

    brand_options = master_df["ãƒ–ãƒ©ãƒ³ãƒ‰"].dropna().unique().tolist()
    if not brand_options:
        st.info("å•†å“ãƒã‚¹ã‚¿ã«ãƒ–ãƒ©ãƒ³ãƒ‰ãŒã‚ã‚Šã¾ã›ã‚“ã€‚å…ˆã«å•†å“ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    selected_brand = st.selectbox("ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’é¸æŠ", brand_options, key="brand_select")

    filtered_df = master_df[master_df["ãƒ–ãƒ©ãƒ³ãƒ‰"] == selected_brand]
    if filtered_df.empty:
        st.info("ã“ã®ãƒ–ãƒ©ãƒ³ãƒ‰ã®å•†å“ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

    # ç®¡ç†ç•ªå·ã‚’æ•°å€¤æ˜‡é †ã«ä¸¦ã¹ã‚‹
    pid_options = filtered_df["ç®¡ç†ç•ªå·"].dropna().unique().tolist()
    pid_options = sorted(
        pid_options,
        key=lambda x: int(re.search(r"\d+", str(x)).group()) if re.search(r"\d+", str(x)) else float("inf")
    )
    selected_pid = st.selectbox("ç®¡ç†ç•ªå·ã‚’é¸æŠ", pid_options, key="pid_select")

    product_group = filtered_df[filtered_df["ç®¡ç†ç•ªå·"] == selected_pid]
    product_row = product_group.iloc[0]
    genre  = product_row["ã‚¸ãƒ£ãƒ³ãƒ«"]
    sizes  = product_group["ã‚µã‚¤ã‚º"].astype(str).tolist()

    st.write(f"**å•†å“åï¼š** {product_row['å•†å“å']}ã€€ã€€**ã‚«ãƒ©ãƒ¼ï¼š** {product_row['ã‚«ãƒ©ãƒ¼']}")

    # 3) æ¡å¯¸é …ç›®ã®ç¢ºå®š
    template_row = template_df[template_df["ã‚¸ãƒ£ãƒ³ãƒ«"] == genre]
    if template_row.empty:
        st.warning("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        st.stop()

    raw_items   = template_row.iloc[0]["æ¡å¯¸é …ç›®"].replace("ã€", ",").split(",")
    all_items   = [re.sub(r'ï¼ˆ.*?ï¼‰', '', i).strip() for i in raw_items if i.strip()]
    custom_order = custom_orders.get(genre, [])
    items = [i for i in custom_order if i in all_items] + [i for i in all_items if i not in custom_order]

    # ---- ä¿å­˜å¾Œã¯ç©ºè¡¨ã§å‡ºã™ä»•çµ„ã¿ï¼ˆè¿½åŠ ï¼‰ ----
    def make_blank_df(sizes, items):
        base = {item: [""] * len(sizes) for item in items}
        base["å‚™è€ƒ"] = [""] * len(sizes)
        df_blank = pd.DataFrame(base, index=[str(s) for s in sizes])
        df_blank.index.name = "ã‚µã‚¤ã‚º"
        return df_blank.astype(str)

    reset_after_save = st.session_state.pop("reset_editor", False)
    # -----------------------------------------

    # æ—¢å­˜å€¤ã‹ç©ºè¡¨ã‹ã‚’æ±ºã‚ã¦ df ã‚’ä½œæˆ
    if reset_after_save:
        df = make_blank_df(sizes, items)
    else:
        data = {item: [] for item in items}
        remarks = []
        for size in sizes:
            row = combined_df[(combined_df["å•†å“ç®¡ç†ç•ªå·"] == selected_pid) &
                              (combined_df["ã‚µã‚¤ã‚º"].astype(str) == str(size))]
            for item in items:
                val = row[item].values[0] if not row.empty and item in row.columns else ""
                data[item].append(val)
            note = row["å‚™è€ƒ"].values[0] if not row.empty and "å‚™è€ƒ" in row.columns else ""
            remarks.append(note)
        data["å‚™è€ƒ"] = remarks
        df = pd.DataFrame(data, index=[str(s) for s in sizes])
        df.index.name = "ã‚µã‚¤ã‚º"
        df = df.astype(str)

    # 4) åŸºæº–å€¤ã®è¡¨ç¤º
    st.markdown("### ğŸ“ è©²å½“å•†å“ã®åŸºæº–å€¤")
    try:
        standard_df = load_standard_data()
        std_row = standard_df[
            (standard_df["å•†å“ç®¡ç†ç•ªå·"] == selected_pid) &
            (standard_df["ã‚µã‚¤ã‚º"].astype(str).isin([str(s) for s in sizes]))
        ]
        if std_row.empty:
            st.info("ã“ã®å•†å“ã«ã¯åŸºæº–å€¤ãƒ‡ãƒ¼ã‚¿ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            std_row = std_row.set_index(std_row["ã‚µã‚¤ã‚º"].astype(str))
            show_cols = [col for col in items if col in std_row.columns]
            show_df = std_row[show_cols].astype(str)
            st.dataframe(show_df, use_container_width=True)
    except Exception as e:
        st.warning(f"åŸºæº–å€¤ã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    # â˜…â˜…â˜… ä¿å­˜å‰ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒ«ã‚’å¼·åˆ¶ç¢ºå®šã•ã›ã‚‹ãƒ•ãƒƒã‚¯ï¼ˆãƒ•ã‚©ãƒ¼ãƒ ç›´å‰ã«æŒ¿å…¥ï¼‰ â˜…â˜…â˜…
    components.html(
        """
        <script>
        const parentDoc = window.parent?.document || document;

        function attachBlurToSaveButtons() {
          // ã™ã§ã«ã‚¢ã‚¿ãƒƒãƒæ¸ˆã¿ãªã‚‰äºŒé‡ã§ä»˜ã‘ãªã„
          const mark = '__blurAttached__';
          const buttons = parentDoc.querySelectorAll('button');
          buttons.forEach((b) => {
            if (b.innerText.trim() === 'ä¿å­˜ã™ã‚‹' && !b[mark]) {
              const blur = () => {
                const el = parentDoc.activeElement;
                if (el && typeof el.blur === 'function') el.blur();
              };
              // ã‚¯ãƒªãƒƒã‚¯ã‚ˆã‚Šå‰ã« blur ã‚’èµ°ã‚‰ã›ã‚‹
              b.addEventListener('mousedown', blur);
              b.addEventListener('touchstart', blur, {passive: true});
              b[mark] = true;
            }
          });
        }

        // åˆå›ã¨é…å»¶å‘¼ã³å‡ºã—ï¼ˆå†æç”»ã¸ã®è€æ€§ï¼‰
        attachBlurToSaveButtons();
        setTimeout(attachBlurToSaveButtons, 400);
        setTimeout(attachBlurToSaveButtons, 1000);
        </script>
        """,
        height=0,
    )
    # â˜…â˜…â˜… ã“ã“ã¾ã§ â˜…â˜…â˜…

# 5) æ¡å¯¸ã‚¨ãƒ‡ã‚£ã‚¿ï¼ˆãƒ•ã‚©ãƒ¼ãƒ ã§åŒ…ã‚€ï¼‰
with st.form("measure_input_form", clear_on_submit=False):
    st.markdown("### âœ æ¡å¯¸")
    edited_df = st.data_editor(
        df,
        use_container_width=True,
        num_rows="dynamic",
        key="measured_editor"
    )
    do_save = st.form_submit_button("ä¿å­˜ã™ã‚‹")

# 6) ä¿å­˜å‡¦ç†
if do_save:
    try:
        # å¿µã®ãŸã‚ session_state ã‹ã‚‰ã‚‚æ‹¾ã†ï¼ˆæœªç¢ºå®šã‚»ãƒ«å¯¾å¿œï¼‰
        edited_df = st.session_state.get("measured_editor", edited_df)

        result_sheet = spreadsheet.worksheet("æ¡å¯¸çµæœ")
        headers = result_sheet.row_values(1)
        saved_sizes = []

        for size in edited_df.index:
            size_str = str(size).strip()
            if not size_str:
                continue
            row_values = (
                edited_df.loc[size, items]
                if set(items).issubset(edited_df.columns)
                else pd.Series(dtype=object)
            )
            if isinstance(row_values, pd.Series) and row_values.replace("", pd.NA).isna().all():
                continue

            save_data = {
                "æ—¥ä»˜": datetime.now().strftime("%Y-%m-%d"),
                "å•†å“ç®¡ç†ç•ªå·": selected_pid,
                "ãƒ–ãƒ©ãƒ³ãƒ‰": selected_brand,
                "ã‚¸ãƒ£ãƒ³ãƒ«": genre,
                "å•†å“å": product_row["å•†å“å"],
                "ã‚«ãƒ©ãƒ¼": product_row["ã‚«ãƒ©ãƒ¼"],
                "ã‚µã‚¤ã‚º": size_str,
                "å‚™è€ƒ": edited_df.loc[size, "å‚™è€ƒ"] if "å‚™è€ƒ" in edited_df.columns else ""
            }
            for item in items:
                save_data[item] = (
                    edited_df.loc[size, item] if item in edited_df.columns else ""
                )

            # Google Sheets ã®åˆ—æ•°ã¨åˆã‚ã›ã‚‹
            new_row = [
                "" if save_data.get(h) is None else str(save_data.get(h))
                for h in headers
            ]
            result_sheet.append_row(new_row)
            saved_sizes.append(size_str)

        # å•†å“ãƒã‚¹ã‚¿æ›´æ–°
        master_sheet = spreadsheet.worksheet("å•†å“ãƒã‚¹ã‚¿")
        full_master_df = pd.DataFrame(master_sheet.get_all_records())
        full_master_df["ã‚µã‚¤ã‚º"] = full_master_df["ã‚µã‚¤ã‚º"].astype(str)
        updated_master_df = full_master_df[~(
            (full_master_df["ç®¡ç†ç•ªå·"] == selected_pid)
            & (full_master_df["ã‚µã‚¤ã‚º"].isin(saved_sizes))
        )]
        master_sheet.clear()
        master_sheet.update(
            [updated_master_df.columns.tolist()]
            + updated_master_df.fillna("").values.tolist()
        )

        # ä¿å­˜å¾Œï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ï¼†ã‚¨ãƒ‡ã‚£ã‚¿åˆæœŸåŒ– â†’ ç©ºè¡¨ã«æ›´æ–°
        load_result_data.clear()
        load_master_data.clear()
        st.session_state.pop("measured_editor", None)  # data_editor ã®å†…éƒ¨çŠ¶æ…‹ã‚’å‰Šé™¤
        st.session_state["reset_editor"] = True        # æ¬¡å›æç”»ã¯ç©ºè¡¨
        st.success("âœ… æ¡å¯¸ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
        st.rerun()  # ã™ãã«ç©ºè¡¨ã¸åˆ‡ã‚Šæ›¿ãˆã‚‹

    except Exception as e:
        st.error(f"ä¿å­˜æ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")


    # 7) å‚è€ƒãƒ†ãƒ¼ãƒ–ãƒ«
    st.markdown("### ğŸ‘• åŒã˜ãƒ¢ãƒ‡ãƒ«ã®éå»æ¡å¯¸ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¯”è¼ƒç”¨ï¼‰")
    try:
        model_prefix = selected_pid[:8]
        model_df = combined_df[
            (combined_df["å•†å“ç®¡ç†ç•ªå·"].astype(str).str[:8] == model_prefix) &
            (combined_df["å•†å“ç®¡ç†ç•ªå·"] != selected_pid)
        ]
        base_cols = ["æ—¥ä»˜", "å•†å“ç®¡ç†ç•ªå·", "ã‚µã‚¤ã‚º"]
        show_cols = base_cols + [c for c in model_df.columns if c in items]
        show_df = model_df[show_cols].sort_values(by=["æ—¥ä»˜", "ã‚µã‚¤ã‚º"], ascending=[False, True])
        st.dataframe(show_df, use_container_width=True)
    except Exception as e:
        st.warning(f"åŒãƒ¢ãƒ‡ãƒ«æ¡å¯¸ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    st.markdown("### ğŸ“… æœ¬æ—¥ç™»éŒ²ã—ãŸæ¡å¯¸ãƒ‡ãƒ¼ã‚¿ä¸€è¦§")
    try:
        today_str = datetime.now().strftime("%Y-%m-%d")
        today_df = combined_df[combined_df["æ—¥ä»˜"] == today_str]
        if not today_df.empty:
            base_cols = ["å•†å“ç®¡ç†ç•ªå·", "ã‚µã‚¤ã‚º"]
            show_cols = base_cols + [col for col in today_df.columns if col in items]
            show_df = today_df[show_cols].sort_values(by=["å•†å“ç®¡ç†ç•ªå·", "ã‚µã‚¤ã‚º"])
            st.dataframe(show_df, use_container_width=True)
        else:
            st.info("ä»Šæ—¥ã¯ã¾ã æ¡å¯¸ãƒ‡ãƒ¼ã‚¿ãŒç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    except Exception as e:
        st.warning(f"ä»Šæ—¥ã®æ¡å¯¸ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")

# ---------------------
# æ¡å¯¸æ¤œç´¢ãƒšãƒ¼ã‚¸ï¼ˆã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¨çµ±åˆæ¤œç´¢ï¼‰
# ---------------------
elif page == "æ¡å¯¸æ¤œç´¢":
    st.title("ğŸ” æ¡å¯¸çµæœæ¤œç´¢")
    try:
        result_values = spreadsheet.worksheet("æ¡å¯¸çµæœ").get_all_values()
        archive_values = spreadsheet.worksheet("æ¡å¯¸ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–").get_all_values()

        def to_df(values):
            if not values:
                return pd.DataFrame()
            headers = values[0]
            data = [row + [''] * (len(headers) - len(row)) for row in values[1:]]
            return pd.DataFrame(data, columns=headers)

        result_df = to_df(result_values)
        archive_df = to_df(archive_values)
        combined_df = pd.concat([result_df, archive_df], ignore_index=True)

        selected_brands = st.multiselect("ğŸ”¸ ãƒ–ãƒ©ãƒ³ãƒ‰ã‚’é¸æŠ", sorted(combined_df["ãƒ–ãƒ©ãƒ³ãƒ‰"].dropna().unique()))
        filtered_df = combined_df[combined_df["ãƒ–ãƒ©ãƒ³ãƒ‰"].isin(selected_brands)] if selected_brands else combined_df

        pid_options = sorted(filtered_df["å•†å“ç®¡ç†ç•ªå·"].dropna().unique())
        size_options = sorted(filtered_df["ã‚µã‚¤ã‚º"].dropna().unique())
        genre_options = sorted(filtered_df["ã‚¸ãƒ£ãƒ³ãƒ«"].dropna().unique())

        selected_pids = st.multiselect("ğŸ”¹ ç®¡ç†ç•ªå·ã‚’é¸æŠ", pid_options)
        selected_sizes = st.multiselect("ğŸ”º ã‚µã‚¤ã‚ºã‚’é¸æŠ", size_options)
        keyword = st.text_input("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ï¼ˆå•†å“åã€ç®¡ç†ç•ªå·ãªã©ï¼‰")
        genre_filter = st.selectbox("ğŸ“‚ ã‚¸ãƒ£ãƒ³ãƒ«ã§è¡¨ç¤ºé …ç›®ã‚’çµã‚‹", ["ã™ã¹ã¦è¡¨ç¤º"] + genre_options)

        df = filtered_df.copy()
        if selected_pids:
            df = df[df["å•†å“ç®¡ç†ç•ªå·"].isin(selected_pids)]
        if selected_sizes:
            df = df[df["ã‚µã‚¤ã‚º"].isin(selected_sizes)]
        if keyword:
            df = df[df.apply(lambda row: keyword.lower() in str(row.values).lower(), axis=1)]
        if genre_filter != "ã™ã¹ã¦è¡¨ç¤º":
            df = df[df["ã‚¸ãƒ£ãƒ³ãƒ«"] == genre_filter]

        base_cols = ["æ—¥ä»˜", "å•†å“ç®¡ç†ç•ªå·", "ãƒ–ãƒ©ãƒ³ãƒ‰", "ã‚¸ãƒ£ãƒ³ãƒ«", "å•†å“å", "ã‚«ãƒ©ãƒ¼", "ã‚µã‚¤ã‚º"]

        # ==== ä¸¦ã³é †ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆã€Œã™ã¹ã¦è¡¨ç¤ºã€å¯¾å¿œï¼‰ ====
        if genre_filter != "ã™ã¹ã¦è¡¨ç¤º":
            ideal_cols = ideal_order_dict.get(genre_filter, [])
        else:
            present_genres = [g for g in df["ã‚¸ãƒ£ãƒ³ãƒ«"].dropna().unique().tolist()]
            if len(present_genres) == 1:
                ideal_cols = ideal_order_dict.get(present_genres[0], [])
            else:
                merged = []
                for g in present_genres:
                    for c in ideal_order_dict.get(g, []):
                        if c not in merged:
                            merged.append(c)
                ideal_cols = merged
        # ===========================================

        ordered_cols = (
            base_cols
            + [c for c in ideal_cols if c in df.columns]
            + [c for c in df.columns if c not in base_cols + ideal_cols]
        )

        df = df[ordered_cols]
        df = df.loc[:, ~(df.isna() | (df == "")).all(axis=0)]

        st.write(f"ğŸ” æ¤œç´¢çµæœ: {len(df)} ä»¶")
        st.dataframe(df, use_container_width=True)

        if not df.empty:
            to_excel = io.BytesIO()
            with pd.ExcelWriter(to_excel, engine="openpyxl") as writer:
                df.to_excel(writer, index=False, sheet_name="æ¡å¯¸çµæœ")
                writer.sheets["æ¡å¯¸çµæœ"].auto_filter.ref = writer.sheets["æ¡å¯¸çµæœ"].dimensions
            to_excel.seek(0)
            st.download_button(
                label="ğŸ“¥ æ¤œç´¢çµæœã‚’Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=to_excel,
                file_name="æ¡å¯¸çµæœ_æ¤œç´¢çµæœ.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    except Exception as e:
        st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# ---------------------
# å•†å“ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸
# ---------------------
elif page == "å•†å“ã‚¤ãƒ³ãƒãƒ¼ãƒˆ":
    st.title("ğŸ“¦ å•†å“ãƒã‚¹ã‚¿ï¼šExcelã‚¤ãƒ³ãƒãƒ¼ãƒˆ")

    uploaded_file = st.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"])
    if uploaded_file:
        df = pd.read_excel(uploaded_file, sheet_name="output", skiprows=0)
        df = df.iloc[:, :7]  # Bã€œHåˆ—ã ã‘ä½¿ã†
        df.columns = ["ç®¡ç†ç•ªå·", "ãƒ–ãƒ©ãƒ³ãƒ‰", "ã‚¸ãƒ£ãƒ³ãƒ«", "å•†å“å", "ã‚«ãƒ©ãƒ¼", "ã‚µã‚¤ã‚º"]
        df = df.dropna(subset=["ç®¡ç†ç•ªå·", "ã‚µã‚¤ã‚º"])

        st.subheader("èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿")
        st.dataframe(df, use_container_width=True)

        if st.button("Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜"):
            try:
                product_sheet = spreadsheet.worksheet("å•†å“ãƒã‚¹ã‚¿")
                existing = pd.DataFrame(product_sheet.get_all_records())
                merged = pd.concat([existing, df], ignore_index=True).drop_duplicates()
                product_sheet.clear()
                product_sheet.update([merged.columns.tolist()] + merged.fillna("").values.tolist())
                st.success("âœ… å•†å“ãƒã‚¹ã‚¿ã«ä¿å­˜ã—ã¾ã—ãŸï¼")
            except Exception as e:
                st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

# ---------------------
# åŸºæº–å€¤ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸
# ---------------------
elif page == "åŸºæº–å€¤ã‚¤ãƒ³ãƒãƒ¼ãƒˆ":
    st.title("ğŸ“ åŸºæº–å€¤ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    uploaded_file = st.file_uploader("åŸºæº–å€¤Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"])
    if uploaded_file:
        try:
            prod_df = pd.read_excel(uploaded_file, sheet_name="å•†å“ãƒã‚¹ã‚¿")
            std_df = pd.read_excel(uploaded_file, sheet_name="åŸºæº–ID")
            merged = pd.merge(prod_df, std_df, on="åŸºæº–ID", how="inner")
            merged = merged.dropna(axis=1, how="all")
            merged["æ—¥ä»˜"] = datetime.now().strftime("%Y-%m-%d")
            st.markdown("### ğŸ‘€ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å†…å®¹ï¼ˆçµ±åˆæ¸ˆï¼‰")
            st.dataframe(merged, use_container_width=True)

            if st.button("Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜"):
                try:
                    sheet = spreadsheet.worksheet("åŸºæº–ãƒ‡ãƒ¼ã‚¿")
                except gspread.exceptions.WorksheetNotFound:
                    sheet = spreadsheet.add_worksheet(title="åŸºæº–ãƒ‡ãƒ¼ã‚¿", rows="100", cols="50")
                exist = pd.DataFrame(sheet.get_all_records())
                if not exist.empty:
                    keys = set(zip(merged["å•†å“ç®¡ç†ç•ªå·"], merged["ã‚µã‚¤ã‚º"]))
                    exist = exist[~exist.apply(lambda r: (r["å•†å“ç®¡ç†ç•ªå·"], r["ã‚µã‚¤ã‚º"]) in keys, axis=1)]
                final = pd.concat([exist, merged], ignore_index=True)
                sheet.clear()
                sheet.update([final.columns.tolist()] + final.fillna("").values.tolist())
                st.success("âœ… åŸºæº–ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
        except Exception as e:
            st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# ---------------------
# æ¡å¯¸ãƒ˜ãƒƒãƒ€ãƒ¼åˆæœŸåŒ–ãƒšãƒ¼ã‚¸
# ---------------------
elif page == "æ¡å¯¸ãƒ˜ãƒƒãƒ€ãƒ¼åˆæœŸåŒ–":
    st.title("ğŸ“‹ æ¡å¯¸ã‚·ãƒ¼ãƒˆ ãƒ˜ãƒƒãƒ€ãƒ¼åˆæœŸåŒ–ï¼ˆâ€»ãƒ‡ãƒ¼ã‚¿ã¯æ®‹ã‚‹ï¼‰")
    headers = ["æ—¥ä»˜","å•†å“ç®¡ç†ç•ªå·","ãƒ–ãƒ©ãƒ³ãƒ‰","ã‚¸ãƒ£ãƒ³ãƒ«","å•†å“å","ã‚«ãƒ©ãƒ¼","ã‚µã‚¤ã‚º",
               "è‚©å¹…","èƒ¸å¹…","èƒ´å›²","è¢–ä¸ˆ","ç€ä¸ˆ","è¥Ÿé«˜","é¦–é«˜","ã‚¦ã‚¨ã‚¹ãƒˆ","è‚¡ä¸Š","è‚¡ä¸‹",
               "ãƒ¯ã‚¿ãƒª","è£¾å¹…","å…¨é•·","æœ€å¤§å¹…","æ¨ªå¹…","é ­å‘¨ã‚Š","ãƒ„ãƒ","é«˜ã•","è£„ä¸ˆ","ãƒ™ãƒ«ãƒˆå¹…","å‰ä¸ˆ","å¾Œä¸ˆ"]
    def reinit(name):
        try:
            ws = spreadsheet.worksheet(name)
            rows = ws.get_all_values()[1:]
            ws.clear()
            ws.append_row(headers)
            if rows:
                norm = [r + [''] * (len(headers) - len(r)) for r in rows]
                ws.append_rows(norm)
            st.success(f"âœ… ã€{name}ã€ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸï¼")
        except Exception as e:
            st.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

    if st.button("ğŸ§¼ æ¡å¯¸çµæœã‚·ãƒ¼ãƒˆã®åˆæœŸåŒ–"):
        reinit("æ¡å¯¸çµæœ")
    if st.button("ğŸ§¼ æ¡å¯¸ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚·ãƒ¼ãƒˆã®åˆæœŸåŒ–"):
        reinit("æ¡å¯¸ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–")

# ---------------------
# ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç®¡ç†ãƒšãƒ¼ã‚¸ï¼ˆ30æ—¥è¶…â†’ç§»å‹•ï¼‰
# ---------------------
elif page == "ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç®¡ç†":
    st.title("ğŸ—ƒï¸ æ¡å¯¸ãƒ‡ãƒ¼ã‚¿ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç®¡ç†")
    def parse_date(s):
        for f in ("%Y-%m-%d","%Y/%m/%d","%Y.%m.%d"):
            try:
                return datetime.strptime(s.strip(), f)
            except:
                pass
        return None

    if st.button("ğŸ“¦ 30æ—¥ä»¥ä¸Šå‰ã®æ¡å¯¸çµæœã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ç§»å‹•"):
        try:
            res = spreadsheet.worksheet("æ¡å¯¸çµæœ")
            arc = spreadsheet.worksheet("æ¡å¯¸ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–")
            vals = res.get_all_values()
            hdr, rows = vals[0], vals[1:]
            old, recent = [], []
            today = datetime.now()
            for r in rows:
                r += [''] * (len(hdr) - len(r))
                d = parse_date(r[0])
                (old if d and (today - d).days > 30 else recent).append(r)
            if old:
                if not arc.get_all_values():
                    arc.append_row(hdr)
                arc.append_rows(old)
            res.clear()
            res.append_row(hdr)
            if recent:
                res.append_rows(recent)
            st.success(f"âœ… {len(old)}ä»¶ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ç§»å‹•ã—ã¾ã—ãŸï¼")
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
